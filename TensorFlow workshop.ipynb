{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow workshop\n",
    "## Basics\n",
    "### Defining the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.constant(3)\n",
    "b = tf.constant(3)\n",
    "c = a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trace c, c.eval() here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    print c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(initial_value=3)\n",
    "b = tf.Variable(initial_value=5)\n",
    "c = a * b\n",
    "sess.run(c, feed_dict={a: 10, b: 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.Variable(initial_value=3)\n",
    "update = tf.assign(a, a + tf.constant(1))\n",
    "# try to sess.run(update) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(update)\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(update)\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print sess.run(a + a, feed_dict={a: 10})\n",
    "print sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "# try running sess.run(a) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a + a, feed_dict={a: 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are a generalization of matrices and vectors to more than two dimensions. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(np.array([[1,2],[3,4]]))\n",
    "b = tf.constant([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.],\n",
       "       [ 3.,  4.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(np.array([[1,2],[3,4]]), dtype=np.float64)\n",
    "b = tf.constant([[1,2],[3,4]], dtype=np.float64)\n",
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the things you can do with numpy on arrays you can do with tensorflow on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   4.],\n",
       "       [  9.,  16.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pow(a, 2).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.],\n",
       "       [ 6.,  8.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a + a).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   4.],\n",
       "       [  9.,  16.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a * a).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.,  10.],\n",
       "       [ 15.,  22.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a, a).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on different devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(3000, 3000), dtype=float64, device=/device:CPU:0)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "3.78189301491\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    a = tf.constant(np.zeros((3000, 3000)))\n",
    "    b = tf.constant(np.zeros((3000, 3000)))\n",
    "    c = tf.matmul(a, b)\n",
    "    print c\n",
    "    started = time.time()\n",
    "    print sess.run(c)\n",
    "    print time.time() - started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_1:0\", shape=(3000, 3000), dtype=float64, device=/device:GPU:0)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "6.80619692802\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    a = tf.constant(np.zeros((3000, 3000)))\n",
    "    b = tf.constant(np.zeros((3000, 3000)))\n",
    "    c = tf.matmul(a, b)\n",
    "    print c\n",
    "    started = time.time()\n",
    "    print sess.run(c)\n",
    "    print time.time() - started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, [None, 784])\n",
    "label = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "logits = tf.matmul(input, W) + b\n",
    "output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(label * tf.log(output), reduction_indices=[1]))\n",
    "correct_samples = tf.reduce_sum(tf.reduce_sum(label * output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.121784970164\n",
      "200 0.641116380692\n",
      "400 0.740849196911\n",
      "600 0.764590203762\n",
      "800 0.804321885109\n",
      "FINAL 0.82025859375\n"
     ]
    }
   ],
   "source": [
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for i in range(1000):\n",
    "        batch_input, batch_label = mnist.train.next_batch(128)\n",
    "        sess.run(train_step, feed_dict={input: batch_input, label: batch_label})\n",
    "        if i % 200 == 0:\n",
    "            print i, sess.run(correct_samples, feed_dict={input: batch_input, label: batch_label}) / 128.0\n",
    "\n",
    "    num_test_samples = mnist.test.images.shape[0]\n",
    "    print \"FINAL\", sess.run(correct_samples, feed_dict={input: mnist.test.images, label: mnist.test.labels}) / num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(output, optimizer=\"sgd\", epochs=1000):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(label * tf.log(output), reduction_indices=[1]))\n",
    "    correct_samples = tf.reduce_sum(tf.reduce_sum(label * output))\n",
    "\n",
    "    if optimizer == \"sgd\":\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    elif optimizer == \"adam\":\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    else:\n",
    "        assert False, optimizer\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for i in range(epochs):\n",
    "        batch_input, batch_label = mnist.train.next_batch(128)\n",
    "        sess.run(train_step, feed_dict={input: batch_input, label: batch_label})\n",
    "        if i % 200 == 0:\n",
    "            print i, sess.run(correct_samples, feed_dict={input: batch_input, label: batch_label}) / 128.0\n",
    "\n",
    "    num_test_samples = mnist.test.images.shape[0]\n",
    "    print \"FINAL\", sess.run(correct_samples, feed_dict={input: mnist.test.images, label: mnist.test.labels}) / num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.zeros([784, 200]))\n",
    "b1 = tf.Variable(tf.zeros([200]))\n",
    "\n",
    "W2 = tf.Variable(tf.zeros([200, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "layer1 = tf.matmul(input, W1) + b1\n",
    "activation1 = tf.nn.sigmoid(layer1)\n",
    "logits = tf.matmul(activation1, W2) + b2\n",
    "output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.106626734138\n",
      "200 0.102996751666\n",
      "400 0.101929455996\n",
      "600 0.101439289749\n",
      "800 0.104079857469\n",
      "FINAL 0.102699694824\n"
     ]
    }
   ],
   "source": [
    "train(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.truncated_normal(shape=[784, 200], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[200]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=[200, 10], stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "layer1 = tf.matmul(input, W1) + b1\n",
    "activation1 = tf.nn.sigmoid(layer1)\n",
    "logits = tf.matmul(activation1, W2) + b2\n",
    "output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0995512455702\n",
      "200 0.551346421242\n",
      "400 0.656971812248\n",
      "600 0.719747543335\n",
      "800 0.776132881641\n",
      "FINAL 0.793150488281\n"
     ]
    }
   ],
   "source": [
    "train(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution(flow, kernel_size, in_maps, out_maps):\n",
    "    W = tf.Variable(tf.truncated_normal(shape=[kernel_size, kernel_size, in_maps, out_maps], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[out_maps]))\n",
    "    return tf.nn.conv2d(flow, W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "def pooling(flow, kernel_size):\n",
    "\n",
    "     return tf.nn.max_pool(flow, ksize=[1, kernel_size, kernel_size, 1], strides=[1, kernel_size, kernel_size, 1], padding='SAME')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I have to use with tf.device(\"/cpu:0\"): on the laptop I use for this presentation due to misconfigured cudnn\n",
    "# Feel free to remove it or replace with /gpu:0 when run on a GPU-enabled machine\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    flow = input\n",
    "\n",
    "    flow = tf.reshape(flow, [-1,28,28,1])\n",
    "\n",
    "    flow = convolution(flow, 5, 1, 32)\n",
    "    flow = tf.nn.relu(flow)\n",
    "    flow = pooling(flow, 2)\n",
    "\n",
    "    flow = convolution(flow, 5, 32, 32)\n",
    "    flow = tf.nn.relu(flow)\n",
    "    flow = pooling(flow, 2)\n",
    "\n",
    "    flow = tf.reshape(flow, [-1, 7 * 7 * 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.truncated_normal(shape=[7 * 7 * 32, 200], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[200]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=[200, 10], stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "\"\"\" note the input to matmul is now flow, not input \"\"\"\n",
    "layer1 = tf.matmul(flow, W1) + b1\n",
    "activation1 = tf.nn.relu(layer1)\n",
    "logits = tf.matmul(activation1, W2) + b2\n",
    "output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0930055379868\n",
      "200 0.779168963432\n",
      "400 0.849575698376\n",
      "600 0.894972443581\n",
      "800 0.919608831406\n",
      "1000 0.886497139931\n",
      "1200 0.93567109108\n",
      "1400 0.968767404556\n",
      "1600 0.942642331123\n",
      "1800 0.939561843872\n",
      "FINAL 0.956352050781\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    train(output, optimizer=\"adam\", epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sequence to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 0, 1, 1, 1, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 1, 1, 1, 0, 0]),\n",
       " ([1, 1, 0, 1, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 1, 1, 0, 1, 1, 1]),\n",
       " ([1, 1, 1, 0, 1, 1, 1, 1, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]),\n",
       " ([1, 0, 1, 0, 1, 0, 0, 1, 1, 1], [0, 1, 0, 1, 0, 1, 1, 0, 0, 0]),\n",
       " ([0, 0, 0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 1, 0, 1, 1, 1, 0, 0, 0]),\n",
       " ([0, 1, 1, 0, 0, 0, 1, 1, 1, 0], [0, 1, 1, 1, 0, 0, 0, 1, 1, 0]),\n",
       " ([0, 1, 1, 0, 1, 1, 1, 1, 0, 0], [0, 0, 1, 1, 1, 1, 0, 1, 1, 0]),\n",
       " ([1, 0, 0, 0, 1, 1, 1, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 1, 1]),\n",
       " ([1, 1, 0, 1, 0, 1, 0, 1, 1, 1], [0, 0, 1, 0, 1, 0, 1, 0, 0, 0]),\n",
       " ([0, 1, 0, 1, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 0, 1, 0])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_sample():\n",
    "    inp = [random.randint(0, 1) for _ in range(10)]\n",
    "    if inp[0] == 1:\n",
    "        out = [1 - x for x in inp]\n",
    "    else:\n",
    "        out = [x for x in reversed(inp)]\n",
    "    return inp, out\n",
    "        \n",
    "train_samples = 12800\n",
    "test_samples = 512\n",
    "samples = [gen_sample() for _ in range(train_samples + test_samples)]\n",
    "\n",
    "input_data = [np.array(x[0]) for x in samples[:train_samples]]\n",
    "label_data = [np.array(x[1]) for x in samples[:train_samples]]\n",
    "\n",
    "input_test = [np.array(x[0]) for x in samples[train_samples:]]\n",
    "label_test = [np.array(x[1]) for x in samples[train_samples:]]\n",
    "\n",
    "samples[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = [tf.placeholder(tf.int32, shape=(None,)) for x in range(10)]\n",
    "labels = [tf.placeholder(tf.int32, shape=(None,)) for x in range(10)]\n",
    "weights = [tf.constant(1.0) for x in range(10)]\n",
    "\n",
    "outputs = labels[-1:] + labels[:-1]\n",
    "\n",
    "# this way we can define a single LSTM cell:\n",
    "single_cell = tf.nn.rnn_cell.BasicLSTMCell(128, state_is_tuple=True) # state_is_tuple is to disable a warning\n",
    "\n",
    "# instead, we will use two layer GRU network\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(128) for x in range(2)])\n",
    "\n",
    "outputs, states = tf.nn.seq2seq.embedding_rnn_seq2seq(inputs, outputs, cell, 2, 2, 128, scope=\"k\")\n",
    "\n",
    "loss = tf.nn.seq2seq.sequence_loss(outputs, labels, weights)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feed_dict(input_data, label_data, fr, to):\n",
    "    batch_input = input_data[fr : to]\n",
    "    batch_input_t = [ [x[i] for x in batch_input] for i in range(10)]\n",
    "    batch_label = label_data[fr : to]\n",
    "    batch_label_t = [ [x[i] for x in batch_label] for i in range(10)]\n",
    "    return dict(zip(inputs + labels, batch_input_t + batch_label_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152143\n",
      "0.0379232\n",
      "0.0132509\n",
      "0.0011804\n",
      "0.00599503\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for batch_start in range(0, len(input_data), 128):\n",
    "        #print batch_start\n",
    "        feed_dict = get_feed_dict(input_data, label_data, batch_start, batch_start + 128)\n",
    "        sess.run(train_step, feed_dict=feed_dict)\n",
    "    print sess.run(loss, feed_dict=get_feed_dict(input_test, label_test, 0, len(input_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 1 1 1 0]\n",
      "[0 1 1 1 1 0 0 1 0 0]\n",
      "[0 1 1 1 1 0 0 1 0 0]\n",
      "\n",
      "[1 1 0 1 0 1 1 0 0 0]\n",
      "[0 0 1 0 1 0 0 1 1 1]\n",
      "[0 0 1 0 1 0 0 1 1 1]\n",
      "\n",
      "[0 1 1 0 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 0 1 1 0]\n",
      "[1 1 1 1 1 1 0 1 1 0]\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "[0 1 0 1 1 0 0 1 1 1]\n",
      "[1 1 1 0 0 1 1 0 1 0]\n",
      "[1 1 1 0 0 1 1 0 1 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 0]\n",
      "[0 1 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 1 0 1 1 0 1 1 1]\n",
      "[0 1 0 1 0 0 1 0 0 0]\n",
      "[0 1 0 1 0 0 1 0 0 0]\n",
      "\n",
      "[0 1 0 0 0 0 0 0 1 1]\n",
      "[1 1 0 0 0 0 0 0 1 0]\n",
      "[1 1 0 0 0 0 0 0 1 0]\n",
      "\n",
      "[1 0 1 0 1 1 1 0 1 0]\n",
      "[0 1 0 1 0 0 0 1 0 1]\n",
      "[0 1 0 1 0 0 0 1 0 1]\n",
      "\n",
      "[0 1 0 0 1 1 0 0 1 1]\n",
      "[1 1 0 0 1 1 0 0 1 0]\n",
      "[1 1 0 0 1 1 0 0 1 0]\n",
      "\n",
      "[1 1 0 0 0 0 1 0 1 0]\n",
      "[0 0 1 1 1 1 0 1 0 1]\n",
      "[0 0 1 1 1 1 0 1 0 1]\n",
      "\n",
      "[1 1 1 1 1 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 1 1 1 0]\n",
      "[0 0 0 0 0 1 1 1 1 0]\n",
      "\n",
      "[1 1 1 1 0 0 1 0 0 1]\n",
      "[0 0 0 0 1 1 0 1 1 0]\n",
      "[0 0 0 0 1 1 0 1 1 0]\n",
      "\n",
      "[1 0 0 1 1 1 0 1 1 1]\n",
      "[0 1 1 0 0 0 1 0 0 0]\n",
      "[0 1 1 0 0 0 1 0 0 0]\n",
      "\n",
      "[0 1 0 1 0 0 1 1 1 0]\n",
      "[0 1 1 1 0 0 1 0 1 0]\n",
      "[0 1 1 1 0 0 1 0 1 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 1 1 1]\n",
      "[0 0 1 1 1 1 1 0 0 0]\n",
      "[0 0 1 1 1 1 1 0 0 0]\n",
      "\n",
      "[1 1 0 1 0 1 0 1 0 1]\n",
      "[0 0 1 0 1 0 1 0 1 0]\n",
      "[0 0 1 0 1 0 1 0 1 0]\n",
      "\n",
      "[0 0 1 0 1 1 0 1 0 0]\n",
      "[0 0 1 0 1 1 0 1 0 0]\n",
      "[0 0 1 0 1 1 0 1 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[0 1 1 1 1 1 0 1 1 1]\n",
      "[0 1 1 1 1 1 0 1 1 1]\n",
      "\n",
      "[0 1 1 1 0 1 0 0 1 0]\n",
      "[0 1 0 0 1 0 1 1 1 0]\n",
      "[0 1 0 0 1 0 1 1 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dict = get_feed_dict(input_test, label_test, 0, 20)\n",
    "computed = [np.argmax(sess.run(output, feed_dict=test_dict), axis=1) for output in outputs]\n",
    "result = [np.array([x[i] for x in computed]) for i in range(20)]\n",
    "\n",
    "for i, o, l in zip(input_test, result, label_test[:20]):\n",
    "    print i\n",
    "    print o\n",
    "    print l\n",
    "    assert all(o == l)\n",
    "    print \"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
